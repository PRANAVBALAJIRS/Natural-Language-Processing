{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**TEXT CLASSIFICATION**\n",
        " - Text preprocessing – stopwords removal and porter stemming algorithm\n",
        " - Word embeddings using keras\n",
        " - Padding the sequence\n",
        " - Fix the vocabulary size\n",
        " - One hot encoding\n",
        " - Construct the sequential model RNN and LSTM\n",
        " - Evaluate with accuracy score\n"
      ],
      "metadata": {
        "id": "VakUH9s2WKH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import TextVectorization, Embedding, LSTM, Dense, Input\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support"
      ],
      "metadata": {
        "id": "ZKPeVmK-To77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **TEXT PRE-PROCESSING - STOPWORDS REMOVAL AND PORTER STEMMING ALGORITHM**"
      ],
      "metadata": {
        "id": "xUX3G_F9Xblz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTDOe5wrTpsc",
        "outputId": "bb3b0eee-8de2-48c4-fcc0-9cb99d385803"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "porter = PorterStemmer()"
      ],
      "metadata": {
        "id": "6ykMREXlUE_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text):\n",
        "    tokens = text.split()\n",
        "    tokens = [porter.stem(word) for word in tokens if word.lower() not in stop_words]\n",
        "    return ' '.join(tokens)"
      ],
      "metadata": {
        "id": "VHKNiHNyUMKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gl5hsN6FUlUk",
        "outputId": "84ff05ad-4ab2-4db3-ff9d-93db84d62c2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-08-17 17:15:52--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‘helper_functions.py’\n",
            "\n",
            "helper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-08-17 17:15:52 (78.4 MB/s) - ‘helper_functions.py’ saved [10246/10246]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from helper_functions import unzip_data, create_tensorboard_callback, plot_loss_curves, compare_historys\n",
        "!wget \"https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\"\n",
        "unzip_data(\"nlp_getting_started.zip\")\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4AZlksJUpwE",
        "outputId": "988213c0-e957-4c20-935a-c2df337b91f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-08-17 17:15:52--  https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.174.207, 74.125.23.207, 74.125.203.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.174.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 607343 (593K) [application/zip]\n",
            "Saving to: ‘nlp_getting_started.zip’\n",
            "\n",
            "nlp_getting_started 100%[===================>] 593.11K   930KB/s    in 0.6s    \n",
            "\n",
            "2024-08-17 17:15:53 (930 KB/s) - ‘nlp_getting_started.zip’ saved [607343/607343]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df_shuffled = train_df.sample(frac=1, random_state=42)"
      ],
      "metadata": {
        "id": "AfgpRkQzUvbM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sentences, val_sentences, train_labels, val_labels = train_test_split(\n",
        "    train_df_shuffled[\"text\"].to_numpy(),\n",
        "    train_df_shuffled[\"target\"].to_numpy(),\n",
        "    test_size=0.1,\n",
        "    random_state=42)"
      ],
      "metadata": {
        "id": "CGetaBGJU0GT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sentences = [preprocess_text(sentence) for sentence in train_sentences]\n",
        "val_sentences = [preprocess_text(sentence) for sentence in val_sentences]"
      ],
      "metadata": {
        "id": "s05PNcD9U3dw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **WORD EMBEDDINGS USING KERAS**"
      ],
      "metadata": {
        "id": "HRFzvp-fYN6I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_vocab_length = 10000\n",
        "max_length = 15\n",
        "embedding_dim = 16"
      ],
      "metadata": {
        "id": "x9nuTZiTU6du"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=max_vocab_length, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(train_sentences)"
      ],
      "metadata": {
        "id": "M4Lo8Qj1U_Vo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sequences = tokenizer.texts_to_sequences(train_sentences)\n",
        "val_sequences = tokenizer.texts_to_sequences(val_sentences)"
      ],
      "metadata": {
        "id": "M8Ae44BmVDV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **PADDING THE SEQUENCE**"
      ],
      "metadata": {
        "id": "k6u0FIeKX2RV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "padded_train_sequences = pad_sequences(train_sequences, maxlen=max_length, padding='post', truncating='post')\n",
        "padded_val_sequences = pad_sequences(val_sequences, maxlen=max_length, padding='post', truncating='post')"
      ],
      "metadata": {
        "id": "0jOS6JR_VF3N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**CONSTRUCT THE SEQUENTAIL MODEL**"
      ],
      "metadata": {
        "id": "Aljh-54ZZb5Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = Input(shape=(max_length,))\n",
        "x = Embedding(input_dim=max_vocab_length, output_dim=embedding_dim, input_length=max_length)(inputs)\n",
        "x = LSTM(64)(x)\n",
        "outputs = Dense(1, activation=\"sigmoid\")(x)\n",
        "model = tf.keras.Model(inputs, outputs, name=\"text_classification_model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tn_u2shjVI5-",
        "outputId": "1133930d-fd98-4f6f-c0bc-8ff35e814f34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "Kop-p45eVLc9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "NHHdaWxgVNLX",
        "outputId": "4e998b52-e35f-4e54-f58a-53f88e7c6574"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"text_classification_model\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"text_classification_model\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m16\u001b[0m)              │         \u001b[38;5;34m160,000\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │          \u001b[38;5;34m20,736\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m65\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">160,000</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">20,736</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m180,801\u001b[0m (706.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">180,801</span> (706.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m180,801\u001b[0m (706.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">180,801</span> (706.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_history = model.fit(padded_train_sequences,\n",
        "                          train_labels,\n",
        "                          epochs=5,\n",
        "                          validation_data=(padded_val_sequences, val_labels),\n",
        "                          callbacks=[create_tensorboard_callback(\"model_logs\", \"LSTM\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZ6j6zGpVOxP",
        "outputId": "52a6e695-dea0-419f-8594-91579a228d9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/LSTM/20240817-171601\n",
            "Epoch 1/5\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.6696 - loss: 0.6036 - val_accuracy: 0.7703 - val_loss: 0.4686\n",
            "Epoch 2/5\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.8583 - loss: 0.3418 - val_accuracy: 0.7835 - val_loss: 0.4741\n",
            "Epoch 3/5\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9134 - loss: 0.2295 - val_accuracy: 0.7743 - val_loss: 0.5186\n",
            "Epoch 4/5\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9365 - loss: 0.1741 - val_accuracy: 0.7612 - val_loss: 0.6599\n",
            "Epoch 5/5\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9529 - loss: 0.1415 - val_accuracy: 0.7690 - val_loss: 0.5995\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_pred_probs = model.predict(padded_val_sequences)\n",
        "model_preds = tf.squeeze(tf.round(model_pred_probs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWOH0r1bVQh5",
        "outputId": "06b304d5-8301-4f37-d6e3-801594632110"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**EVALUATE THE ACCURACY SCORE**"
      ],
      "metadata": {
        "id": "2UEBrM9SZOFw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_results(y_true, y_pred):\n",
        "    model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
        "    model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
        "    model_results = {\"accuracy\": model_accuracy,\n",
        "                     \"precision\": model_precision,\n",
        "                     \"recall\": model_recall,\n",
        "                     \"f1\": model_f1}\n",
        "    return model_results"
      ],
      "metadata": {
        "id": "OgGEpRI8VSla"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_results = calculate_results(y_true=val_labels, y_pred=model_preds)\n",
        "print(model_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOhMrvxWVU8E",
        "outputId": "80d11e10-f9b2-4324-991d-1f05c6ecd6e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'accuracy': 76.9028871391076, 'precision': 0.7798518825968084, 'recall': 0.7690288713910761, 'f1': 0.7634085385385204}\n"
          ]
        }
      ]
    }
  ]
}