{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**TEXT PRE-PROCESSING**\n",
        "- REMOVING PUNCTUATION, URL AND UPPER CASING\n",
        "- SEGMENTATION\n",
        "- TOKENIZATION\n",
        "- REMOVING STOP WORDS\n",
        "- STEMMING\n",
        "- LEMMATIZATION\n",
        "- PART OF SPEECH TAGGING (POS)\n",
        "- NAMED ENTITY TAGGING\n",
        "\n",
        "\n",
        "DATASET USED - **PubMed 200K RCT**"
      ],
      "metadata": {
        "id": "XoMr9YC1WC-v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GETTING DATA"
      ],
      "metadata": {
        "id": "BoCPZgQPaB_8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Franck-Dernoncourt/pubmed-rct.git\n",
        "!ls pubmed-rct"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_j0CYt1Z5hO",
        "outputId": "499163fa-3767-4099-d9c1-93c8bf791077"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'pubmed-rct' already exists and is not an empty directory.\n",
            "PubMed_200k_RCT\t\t\t\t       PubMed_20k_RCT_numbers_replaced_with_at_sign\n",
            "PubMed_200k_RCT_numbers_replaced_with_at_sign  README.md\n",
            "PubMed_20k_RCT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = \"pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/\""
      ],
      "metadata": {
        "id": "uUQIVXSKaRvM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_lines(filename):\n",
        "  with open(filename, \"r\") as f:\n",
        "    return f.readlines()"
      ],
      "metadata": {
        "id": "nu4QWPj2aeYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_lines = get_lines(data_dir+\"train.txt\")\n",
        "train_lines[:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8N0w2-J9a18s",
        "outputId": "7c0bbdc2-f577-4018-c38e-295527deaf1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['###24293578\\n',\n",
              " 'OBJECTIVE\\tTo investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( OA ) .\\n',\n",
              " 'METHODS\\tA total of @ patients with primary knee OA were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .\\n',\n",
              " 'METHODS\\tOutcome measures included pain reduction and improvement in function scores and systemic inflammation markers .\\n',\n",
              " 'METHODS\\tPain was assessed using the visual analog pain scale ( @-@ mm ) .\\n',\n",
              " 'METHODS\\tSecondary outcome measures included the Western Ontario and McMaster Universities Osteoarthritis Index scores , patient global assessment ( PGA ) of the severity of knee OA , and @-min walk distance ( @MWD ) .\\n',\n",
              " 'METHODS\\tSerum levels of interleukin @ ( IL-@ ) , IL-@ , tumor necrosis factor ( TNF ) - , and high-sensitivity C-reactive protein ( hsCRP ) were measured .\\n',\n",
              " 'RESULTS\\tThere was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , PGA , and @MWD at @ weeks .\\n',\n",
              " 'RESULTS\\tThe mean difference between treatment arms ( @ % CI ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .\\n',\n",
              " 'RESULTS\\tFurther , there was a clinically relevant reduction in the serum levels of IL-@ , IL-@ , TNF - , and hsCRP at @ weeks in the intervention group when compared to the placebo group .\\n',\n",
              " 'RESULTS\\tThese differences remained significant at @ weeks .\\n',\n",
              " 'RESULTS\\tThe Outcome Measures in Rheumatology Clinical Trials-Osteoarthritis Research Society International responder rate was @ % in the intervention group and @ % in the placebo group ( p < @ ) .\\n',\n",
              " 'CONCLUSIONS\\tLow-dose oral prednisolone had both a short-term and a longer sustained effect resulting in less knee pain , better physical function , and attenuation of systemic inflammation in older patients with knee OA ( ClinicalTrials.gov identifier NCT@ ) .\\n',\n",
              " '\\n',\n",
              " '###24854809\\n',\n",
              " 'BACKGROUND\\tEmotional eating is associated with overeating and the development of obesity .\\n',\n",
              " 'BACKGROUND\\tYet , empirical evidence for individual ( trait ) differences in emotional eating and cognitive mechanisms that contribute to eating during sad mood remain equivocal .\\n',\n",
              " 'OBJECTIVE\\tThe aim of this study was to test if attention bias for food moderates the effect of self-reported emotional eating during sad mood ( vs neutral mood ) on actual food intake .\\n',\n",
              " 'OBJECTIVE\\tIt was expected that emotional eating is predictive of elevated attention for food and higher food intake after an experimentally induced sad mood and that attentional maintenance on food predicts food intake during a sad versus a neutral mood .\\n',\n",
              " 'METHODS\\tParticipants ( N = @ ) were randomly assigned to one of the two experimental mood induction conditions ( sad/neutral ) .\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1) REMOVING URL"
      ],
      "metadata": {
        "id": "1zxSv6J_ZjQm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u25axrGpMRBO",
        "outputId": "c38f9201-c4b6-4df1-f6b4-abbf1e3948b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Line with URL:\n",
            "BACKGROUND\thttp://www.clinicaltrials.gov number NCT@ .\n",
            "\n",
            "\n",
            "Cleaned Line without URL:\n",
            "BACKGROUND\t number NCT@ .\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "def remove_urls(text):\n",
        "    return re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
        "\n",
        "cleaned_lines_urls = [remove_urls(line) for line in train_lines]\n",
        "\n",
        "for line in train_lines:\n",
        "    if re.search(r'http\\S+|www\\S+|https\\S+', line):\n",
        "        print(\"Original Line with URL:\")\n",
        "        print(line)\n",
        "\n",
        "        cleaned_line = remove_urls(line)\n",
        "\n",
        "        print(\"\\nCleaned Line without URL:\")\n",
        "        print(cleaned_line)\n",
        "        break\n",
        "\n",
        "with open(\"cleaned_train_urls.txt\", \"w\") as f:\n",
        "    f.writelines(cleaned_lines_urls)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2) REMOVING PUNCTUATION"
      ],
      "metadata": {
        "id": "O7PvQb4Yd9cl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_punctuation(text):\n",
        "    return re.sub(r'[^\\w\\s]', '', text)\n",
        "\n",
        "cleaned_lines_punctuation = [remove_punctuation(line) for line in cleaned_lines_urls]\n",
        "\n",
        "for line in cleaned_lines_urls:\n",
        "    if re.search(r'[^\\w\\s]', line):\n",
        "        print(\"Original Line with Punctuation:\")\n",
        "        print(line)\n",
        "\n",
        "        cleaned_line = remove_punctuation(line)\n",
        "\n",
        "        print(\"\\nCleaned Line without Punctuation:\")\n",
        "        print(cleaned_line)\n",
        "        break\n",
        "\n",
        "with open(\"cleaned_train_punctuation.txt\", \"w\") as f:\n",
        "    f.writelines(cleaned_lines_punctuation)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oerpzuAreb-N",
        "outputId": "d6edd4d3-8a4c-493a-bf9d-f7b83fe09d8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Line with Punctuation:\n",
            "###24293578\n",
            "\n",
            "\n",
            "Cleaned Line without Punctuation:\n",
            "24293578\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3) REPLACING UPPER CASE WITH LOWER CASE"
      ],
      "metadata": {
        "id": "gm5OODIyehvH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_lowercase(text):\n",
        "    return text.lower()\n",
        "\n",
        "with open(\"cleaned_train_urls.txt\", \"r\") as f:\n",
        "    cleaned_lines_urls = f.readlines()\n",
        "\n",
        "cleaned_lines_lowercase = [convert_to_lowercase(line) for line in cleaned_lines_urls]\n",
        "\n",
        "for line in cleaned_lines_urls:\n",
        "    if any(char.isupper() for char in line):\n",
        "        print(\"Original Line with Uppercase Characters:\")\n",
        "        print(line)\n",
        "\n",
        "        cleaned_line = convert_to_lowercase(line)\n",
        "\n",
        "        print(\"\\nCleaned Line with Lowercase Characters:\")\n",
        "        print(cleaned_line)\n",
        "        break\n",
        "\n",
        "with open(\"cleaned_train_lowercase.txt\", \"w\") as f:\n",
        "    f.writelines(cleaned_lines_lowercase)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTnoRIRcedfF",
        "outputId": "99c4d397-c5c6-4dcf-b11a-a7693d7ab864"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Line with Uppercase Characters:\n",
            "OBJECTIVE\tTo investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( OA ) .\n",
            "\n",
            "\n",
            "Cleaned Line with Lowercase Characters:\n",
            "objective\tto investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4) SEGMENTATION"
      ],
      "metadata": {
        "id": "p9uAxS0DhNzE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize"
      ],
      "metadata": {
        "id": "fmMn8TmwiUY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "\n",
        "with open(\"cleaned_train_lowercase.txt\", \"r\") as f:\n",
        "    cleaned_lines_lowercase = f.readlines()\n",
        "\n",
        "def segment_sentences(text):\n",
        "    return sent_tokenize(text)\n",
        "\n",
        "segmented_lines = [segment_sentences(line) for line in cleaned_lines_lowercase]\n",
        "\n",
        "for line in cleaned_lines_lowercase:\n",
        "    if '.' in line:\n",
        "        print(\"Original Line:\")\n",
        "        print(line)\n",
        "\n",
        "        segmented_line = segment_sentences(line)\n",
        "\n",
        "        print(\"\\nSegmented Sentences:\")\n",
        "        for sentence in segmented_line:\n",
        "            print(sentence)\n",
        "        break\n",
        "\n",
        "with open(\"segmented_train.txt\", \"w\") as f:\n",
        "    for sentences in segmented_lines:\n",
        "        f.write('\\n'.join(sentences) + '\\n')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPzugLDUg4j2",
        "outputId": "a40782e1-9124-4703-882b-60f750c4d2c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Line:\n",
            "objective\tto investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .\n",
            "\n",
            "\n",
            "Segmented Sentences:\n",
            "objective\tto investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5) TOKENIZATION"
      ],
      "metadata": {
        "id": "Yywpi_a7ieRR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-HeZp1EZi8Hz",
        "outputId": "f7bd69ca-b5d2-4dbc-adff-594eeb34aae6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"segmented_train.txt\", \"r\") as f:\n",
        "    segmented_lines = f.readlines()\n",
        "\n",
        "def tokenize(text):\n",
        "    return word_tokenize(text)\n",
        "\n",
        "tokenized_lines = [tokenize(sentence) for line in segmented_lines for sentence in line.split('\\n') if sentence.strip()]\n",
        "\n",
        "sentence_count = 0\n",
        "for line in segmented_lines:\n",
        "    sentences = line.split('\\n')\n",
        "    for sentence in sentences:\n",
        "        if sentence.strip():\n",
        "            sentence_count += 1\n",
        "            if sentence_count == 2:\n",
        "                print(\"Original Sentence:\")\n",
        "                print(sentence)\n",
        "\n",
        "                tokens = tokenize(sentence)\n",
        "\n",
        "                print(\"\\nTokenized Sentence:\")\n",
        "                print(tokens)\n",
        "                print(\"\\n\" + \"-\"*40)\n",
        "                break\n",
        "    if sentence_count == 2:\n",
        "        break\n",
        "\n",
        "with open(\"tokenized_train.txt\", \"w\") as f:\n",
        "    for tokens in tokenized_lines:\n",
        "        f.write(' '.join(tokens) + '\\n')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8andjWqzATE",
        "outputId": "18b44b52-5f3d-46cc-842f-db5841ec2fbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Sentence:\n",
            "objective\tto investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .\n",
            "\n",
            "Tokenized Sentence:\n",
            "['objective', 'to', 'investigate', 'the', 'efficacy', 'of', '@', 'weeks', 'of', 'daily', 'low-dose', 'oral', 'prednisolone', 'in', 'improving', 'pain', ',', 'mobility', ',', 'and', 'systemic', 'low-grade', 'inflammation', 'in', 'the', 'short', 'term', 'and', 'whether', 'the', 'effect', 'would', 'be', 'sustained', 'at', '@', 'weeks', 'in', 'older', 'adults', 'with', 'moderate', 'to', 'severe', 'knee', 'osteoarthritis', '(', 'oa', ')', '.']\n",
            "\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6) REMOVING STOP WORDS"
      ],
      "metadata": {
        "id": "KR1akBx3j05-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "XUFhAGIylxfU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"tokenized_train.txt\", \"r\") as f:\n",
        "    tokenized_lines = [line.split() for line in f.readlines()]\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def remove_stop_words(tokens):\n",
        "    return [word for word in tokens if word.lower() not in stop_words]\n",
        "\n",
        "cleaned_lines = [remove_stop_words(tokens) for tokens in tokenized_lines]\n",
        "\n",
        "sentence_count = 0\n",
        "for tokens in tokenized_lines:\n",
        "    if tokens:\n",
        "        sentence_count += 1\n",
        "        if sentence_count == 2:\n",
        "            original_tokens = tokens\n",
        "            cleaned_tokens = remove_stop_words(tokens)\n",
        "\n",
        "            print(\"Original Tokens:\")\n",
        "            print(original_tokens)\n",
        "\n",
        "            print(\"\\nTokens after Removing Stop Words:\")\n",
        "            print(cleaned_tokens)\n",
        "            print(\"\\n\" + \"-\"*40)\n",
        "            break\n",
        "\n",
        "with open(\"cleaned_stopwords_train.txt\", \"w\") as f:\n",
        "    for tokens in cleaned_lines:\n",
        "        f.write(' '.join(tokens) + '\\n')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BaVucYLEzfAZ",
        "outputId": "588d7b95-b25e-430f-c970-92498ef2c6d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Tokens:\n",
            "['objective', 'to', 'investigate', 'the', 'efficacy', 'of', '@', 'weeks', 'of', 'daily', 'low-dose', 'oral', 'prednisolone', 'in', 'improving', 'pain', ',', 'mobility', ',', 'and', 'systemic', 'low-grade', 'inflammation', 'in', 'the', 'short', 'term', 'and', 'whether', 'the', 'effect', 'would', 'be', 'sustained', 'at', '@', 'weeks', 'in', 'older', 'adults', 'with', 'moderate', 'to', 'severe', 'knee', 'osteoarthritis', '(', 'oa', ')', '.']\n",
            "\n",
            "Tokens after Removing Stop Words:\n",
            "['objective', 'investigate', 'efficacy', '@', 'weeks', 'daily', 'low-dose', 'oral', 'prednisolone', 'improving', 'pain', ',', 'mobility', ',', 'systemic', 'low-grade', 'inflammation', 'short', 'term', 'whether', 'effect', 'would', 'sustained', '@', 'weeks', 'older', 'adults', 'moderate', 'severe', 'knee', 'osteoarthritis', '(', 'oa', ')', '.']\n",
            "\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7) STEMMING"
      ],
      "metadata": {
        "id": "ZjRVLdalmFky"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer"
      ],
      "metadata": {
        "id": "4yepRU2pmYnE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"tokenized_train.txt\", \"r\") as f:\n",
        "    tokenized_lines = [line.split() for line in f.readlines()]\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "def apply_stemming(tokens):\n",
        "    return [stemmer.stem(word) for word in tokens]\n",
        "\n",
        "stemmed_lines = [apply_stemming(tokens) for tokens in tokenized_lines]\n",
        "\n",
        "sentence_count = 0\n",
        "for tokens in tokenized_lines:\n",
        "    if tokens:\n",
        "        sentence_count += 1\n",
        "        if sentence_count == 2:\n",
        "            original_tokens = tokens\n",
        "            stemmed_tokens = apply_stemming(tokens)\n",
        "\n",
        "            print(\"Original Tokens:\")\n",
        "            print(original_tokens)\n",
        "\n",
        "            print(\"\\nTokens after Stemming:\")\n",
        "            print(stemmed_tokens)\n",
        "            print(\"\\n\" + \"-\"*40)\n",
        "            break\n",
        "\n",
        "with open(\"stemmed_train.txt\", \"w\") as f:\n",
        "    for tokens in stemmed_lines:\n",
        "        f.write(' '.join(tokens) + '\\n')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1F8E6BdzuLH",
        "outputId": "6b4e71d7-c4f0-4f7d-8205-e5e673c062b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Tokens:\n",
            "['objective', 'to', 'investigate', 'the', 'efficacy', 'of', '@', 'weeks', 'of', 'daily', 'low-dose', 'oral', 'prednisolone', 'in', 'improving', 'pain', ',', 'mobility', ',', 'and', 'systemic', 'low-grade', 'inflammation', 'in', 'the', 'short', 'term', 'and', 'whether', 'the', 'effect', 'would', 'be', 'sustained', 'at', '@', 'weeks', 'in', 'older', 'adults', 'with', 'moderate', 'to', 'severe', 'knee', 'osteoarthritis', '(', 'oa', ')', '.']\n",
            "\n",
            "Tokens after Stemming:\n",
            "['object', 'to', 'investig', 'the', 'efficaci', 'of', '@', 'week', 'of', 'daili', 'low-dos', 'oral', 'prednisolon', 'in', 'improv', 'pain', ',', 'mobil', ',', 'and', 'system', 'low-grad', 'inflamm', 'in', 'the', 'short', 'term', 'and', 'whether', 'the', 'effect', 'would', 'be', 'sustain', 'at', '@', 'week', 'in', 'older', 'adult', 'with', 'moder', 'to', 'sever', 'knee', 'osteoarthr', '(', 'oa', ')', '.']\n",
            "\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8) LEMMATIZATION"
      ],
      "metadata": {
        "id": "Ozf8DdJUmxmZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "id": "780IJ9lynGr8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"tokenized_train.txt\", \"r\") as f:\n",
        "    tokenized_lines = [line.split() for line in f.readlines()]\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def apply_lemmatization(tokens):\n",
        "    return [lemmatizer.lemmatize(word) for word in tokens]\n",
        "\n",
        "lemmatized_lines = [apply_lemmatization(tokens) for tokens in tokenized_lines]\n",
        "\n",
        "sentence_count = 0\n",
        "for tokens in tokenized_lines:\n",
        "    if tokens:\n",
        "        sentence_count += 1\n",
        "        if sentence_count == 2:\n",
        "            original_tokens = tokens\n",
        "            lemmatized_tokens = apply_lemmatization(tokens)\n",
        "\n",
        "            print(\"Original Tokens:\")\n",
        "            print(original_tokens)\n",
        "\n",
        "            print(\"\\nTokens after Lemmatization:\")\n",
        "            print(lemmatized_tokens)\n",
        "            print(\"\\n\" + \"-\"*40)\n",
        "            break\n",
        "\n",
        "with open(\"lemmatized_train.txt\", \"w\") as f:\n",
        "    for tokens in lemmatized_lines:\n",
        "        f.write(' '.join(tokens) + '\\n')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nACVlUa21FX5",
        "outputId": "491abfc7-d167-4499-a420-ea81a7c99502"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Tokens:\n",
            "['objective', 'to', 'investigate', 'the', 'efficacy', 'of', '@', 'weeks', 'of', 'daily', 'low-dose', 'oral', 'prednisolone', 'in', 'improving', 'pain', ',', 'mobility', ',', 'and', 'systemic', 'low-grade', 'inflammation', 'in', 'the', 'short', 'term', 'and', 'whether', 'the', 'effect', 'would', 'be', 'sustained', 'at', '@', 'weeks', 'in', 'older', 'adults', 'with', 'moderate', 'to', 'severe', 'knee', 'osteoarthritis', '(', 'oa', ')', '.']\n",
            "\n",
            "Tokens after Lemmatization:\n",
            "['objective', 'to', 'investigate', 'the', 'efficacy', 'of', '@', 'week', 'of', 'daily', 'low-dose', 'oral', 'prednisolone', 'in', 'improving', 'pain', ',', 'mobility', ',', 'and', 'systemic', 'low-grade', 'inflammation', 'in', 'the', 'short', 'term', 'and', 'whether', 'the', 'effect', 'would', 'be', 'sustained', 'at', '@', 'week', 'in', 'older', 'adult', 'with', 'moderate', 'to', 'severe', 'knee', 'osteoarthritis', '(', 'oa', ')', '.']\n",
            "\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9) PART OF SPEECH TAGGING"
      ],
      "metadata": {
        "id": "ODothSDhng58"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import pos_tag\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "id": "URgmlfKIoYmb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"lemmatized_train.txt\", \"r\") as f:\n",
        "    lemmatized_lines = [line.split() for line in f.readlines()]\n",
        "\n",
        "def pos_tag_tokens(tokens):\n",
        "    return pos_tag(tokens)\n",
        "\n",
        "tagged_lines = [pos_tag_tokens(tokens) for tokens in lemmatized_lines]\n",
        "\n",
        "sentence_count = 0\n",
        "for tokens in lemmatized_lines:\n",
        "    if tokens:\n",
        "        sentence_count += 1\n",
        "        if sentence_count == 2:\n",
        "            original_tokens = tokens\n",
        "            tagged_tokens = pos_tag_tokens(tokens)\n",
        "\n",
        "            print(\"Original Tokens:\")\n",
        "            print(original_tokens)\n",
        "\n",
        "            print(\"\\nPOS Tagged Tokens:\")\n",
        "            print(tagged_tokens)\n",
        "            print(\"\\n\" + \"-\"*40)\n",
        "            break\n",
        "\n",
        "with open(\"tagged_train.txt\", \"w\") as f:\n",
        "    for tagged_tokens in tagged_lines:\n",
        "        f.write(' '.join([f'{word}/{tag}' for word, tag in tagged_tokens]) + '\\n')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Hjls4-NoG9Y",
        "outputId": "8bb77e98-e1aa-45e1-b9eb-9f8f518ce11d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Tokens:\n",
            "['objective', 'to', 'investigate', 'the', 'efficacy', 'of', '@', 'week', 'of', 'daily', 'low-dose', 'oral', 'prednisolone', 'in', 'improving', 'pain', ',', 'mobility', ',', 'and', 'systemic', 'low-grade', 'inflammation', 'in', 'the', 'short', 'term', 'and', 'whether', 'the', 'effect', 'would', 'be', 'sustained', 'at', '@', 'week', 'in', 'older', 'adult', 'with', 'moderate', 'to', 'severe', 'knee', 'osteoarthritis', '(', 'oa', ')', '.']\n",
            "\n",
            "POS Tagged Tokens:\n",
            "[('objective', 'JJ'), ('to', 'TO'), ('investigate', 'VB'), ('the', 'DT'), ('efficacy', 'NN'), ('of', 'IN'), ('@', 'JJ'), ('week', 'NN'), ('of', 'IN'), ('daily', 'JJ'), ('low-dose', 'JJ'), ('oral', 'JJ'), ('prednisolone', 'NN'), ('in', 'IN'), ('improving', 'VBG'), ('pain', 'NN'), (',', ','), ('mobility', 'NN'), (',', ','), ('and', 'CC'), ('systemic', 'JJ'), ('low-grade', 'JJ'), ('inflammation', 'NN'), ('in', 'IN'), ('the', 'DT'), ('short', 'JJ'), ('term', 'NN'), ('and', 'CC'), ('whether', 'IN'), ('the', 'DT'), ('effect', 'NN'), ('would', 'MD'), ('be', 'VB'), ('sustained', 'VBN'), ('at', 'IN'), ('@', 'NNP'), ('week', 'NN'), ('in', 'IN'), ('older', 'JJR'), ('adult', 'NN'), ('with', 'IN'), ('moderate', 'JJ'), ('to', 'TO'), ('severe', 'VB'), ('knee', 'NN'), ('osteoarthritis', 'NN'), ('(', '('), ('oa', 'NN'), (')', ')'), ('.', '.')]\n",
            "\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 10) NAMED ENTITY TAGGING"
      ],
      "metadata": {
        "id": "2swWUWOTopMs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import pos_tag, word_tokenize, ne_chunk\n",
        "from nltk.tree import Tree\n",
        "\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WcTrjlKzo73U",
        "outputId": "5c46f27a-7bbc-4ff4-cbc0-9c0c564dae29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_subset(filename, num_lines=5):\n",
        "    with open(filename, \"r\") as f:\n",
        "        lines = f.readlines()\n",
        "    return [line.split() for line in lines[:num_lines]]\n",
        "\n",
        "tagged_subset = load_subset(\"tagged_train.txt\", num_lines=5)\n",
        "\n",
        "def named_entity_recognition(tokens):\n",
        "    pos_tags = pos_tag(tokens)\n",
        "    return ne_chunk(pos_tags)\n",
        "\n",
        "ner_subset = [named_entity_recognition(tokens) for tokens in tagged_subset]\n",
        "\n",
        "def format_ner_tree(tree):\n",
        "    result = []\n",
        "    for subtree in tree:\n",
        "        if isinstance(subtree, Tree):\n",
        "            result.append(f'{\" \".join(word for word, tag in subtree.leaves())}/{subtree.label()}')\n",
        "        else:\n",
        "            result.append(f'{subtree[0]}/{subtree[1]}')\n",
        "    return ' '.join(result)\n",
        "\n",
        "if len(tagged_subset) >= 2:\n",
        "    tokens = tagged_subset[1]\n",
        "    ner_tree = ner_subset[1]\n",
        "\n",
        "    print(\"Original Tokens:\")\n",
        "    print(tokens)\n",
        "\n",
        "    print(\"\\nNamed Entity Tagged Tokens:\")\n",
        "    print(format_ner_tree(ner_tree))\n",
        "else:\n",
        "    print(\"The subset does not contain enough sentences.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTD-dxBKod4C",
        "outputId": "03481153-6ea4-4a8f-f884-a2bffd30d854"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Tokens:\n",
            "['objective/JJ', 'to/TO', 'investigate/VB', 'the/DT', 'efficacy/NN', 'of/IN', '@/JJ', 'week/NN', 'of/IN', 'daily/JJ', 'low-dose/JJ', 'oral/JJ', 'prednisolone/NN', 'in/IN', 'improving/VBG', 'pain/NN', ',/,', 'mobility/NN', ',/,', 'and/CC', 'systemic/JJ', 'low-grade/JJ', 'inflammation/NN', 'in/IN', 'the/DT', 'short/JJ', 'term/NN', 'and/CC', 'whether/IN', 'the/DT', 'effect/NN', 'would/MD', 'be/VB', 'sustained/VBN', 'at/IN', '@/NNP', 'week/NN', 'in/IN', 'older/JJR', 'adult/NN', 'with/IN', 'moderate/JJ', 'to/TO', 'severe/VB', 'knee/NN', 'osteoarthritis/NN', '(/(', 'oa/NN', ')/)', './.']\n",
            "\n",
            "Named Entity Tagged Tokens:\n",
            "objective/JJ/JJ to/TO/NN investigate/VB/NN the/DT/NN efficacy/NN/NN of/IN/NN @/JJ/NNP week/NN/NN of/IN/NN daily/JJ/VBZ low-dose/JJ/JJ oral/JJ/NN prednisolone/NN/NN in/IN/NN improving/VBG/NN pain/NN/NN ,/,/NNP mobility/NN/NN ,/,/NNP and/CC/VBZ systemic/JJ/JJ low-grade/JJ/JJ inflammation/NN/NN in/IN/NN the/DT/NN short/JJ/NN term/NN/NN and/CC/NN whether/IN/NN the/DT/NN effect/NN/NN would/MD/NN be/VB/NN sustained/VBN/NN at/IN/NN @/NNP/NNP week/NN/NN in/IN/NN older/JJR/NN adult/NN/NN with/IN/NN moderate/JJ/NN to/TO/NN severe/VB/NN knee/NN/NN osteoarthritis/NN/NN (/(/NNP oa/NN/VBZ )/)/CD ././NN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SDEgqeoppU1T"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}